import streamlit as st
import pytesseract
import fitz  # PyMuPDF
from PIL import Image, ImageEnhance, ImageOps
import sys
import shutil
import time
import streamlit.components.v1 as components

# --- C·∫§U H√åNH ---
if sys.platform.startswith('win'):
    PATH_TESSERACT = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
else:
    PATH_TESSERACT = shutil.which("tesseract")

if PATH_TESSERACT:
    pytesseract.pytesseract.tesseract_cmd = PATH_TESSERACT

# --- H√ÄM X·ª¨ L√ù ·∫¢NH (LITE) ---
@st.cache_data(show_spinner=False)
def get_page_lite(pdf_bytes, page_number):
    try:
        doc = fitz.open(stream=pdf_bytes, filetype="pdf")
        page = doc.load_page(page_number - 1)
        
        # Matrix 1.2 cho nh·∫π m√°y
        mat = fitz.Matrix(1.2, 1.2) 
        pix = page.get_pixmap(matrix=mat, alpha=False)
        img_visual = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)
        
        # OCR
        img_ocr = ImageOps.grayscale(img_visual)
        img_ocr = ImageEnhance.Contrast(img_ocr).enhance(1.5)
        
        custom_config = r'--oem 3 --psm 6'
        text = pytesseract.image_to_string(img_ocr, lang='vie', config=custom_config)
        
        # L√†m s·∫°ch c∆° b·∫£n
        text = text.replace('\n', ' ').replace('|', '').strip()
        
        return img_visual, text
    except Exception as e:
        return None, str(e)

# --- JS ƒê·ªåC T·ª™NG C√ÇU (CH·ªêNG NG·∫ÆT QU√ÉNG) ---
def mobile_speak_smooth(text):
    # L·ªçc k√Ω t·ª± g√¢y l·ªói
    safe_text = text.replace('\\', '').replace('"', '').replace("'", "").replace('\n', ' ')
    
    html = f"""
    <script>
        // 1. H·ªßy l·ªánh c≈©
        window.speechSynthesis.cancel();
        
        // 2. Chia vƒÉn b·∫£n th√†nh m·∫£ng c√°c c√¢u (D·ª±a v√†o d·∫•u . ! ? ;)
        var fullText = "{safe_text}";
        // Regex n√†y t√°ch c√¢u nh∆∞ng gi·ªØ l·∫°i d·∫•u c√¢u ƒë·ªÉ ƒë·ªçc c√≥ ng·ªØ ƒëi·ªáu
        var sentences = fullText.match(/[^.!?]+[.!?]+|[^.!?]+$/g);
        
        if (!sentences || sentences.length === 0) {{
            sentences = [fullText]; // N·∫øu kh√¥ng chia ƒë∆∞·ª£c th√¨ ƒë·ªçc c·∫£ c·ª•c
        }}

        var currentIndex = 0;

        function playNextChunk() {{
            // N·∫æU ƒê√É ƒê·ªåC H·∫æT C√ÅC C√ÇU -> B·∫§M NEXT TRANG
            if (currentIndex >= sentences.length) {{
                console.log("Xong trang. Chuy·ªÉn ti·∫øp...");
                var buttons = window.parent.document.getElementsByTagName('button');
                for (var i = 0; i < buttons.length; i++) {{
                    if (buttons[i].innerText.toUpperCase().includes("TI·∫æP THEO")) {{
                        buttons[i].click(); return;
                    }}
                }}
                return;
            }}

            var chunk = sentences[currentIndex];
            if (!chunk || chunk.trim().length === 0) {{
                currentIndex++; playNextChunk(); return;
            }}

            // T·∫†O L·ªÜNH ƒê·ªåC CHO C√ÇU HI·ªÜN T·∫†I
            var msg = new SpeechSynthesisUtterance();
            msg.text = chunk;
            msg.lang = 'vi-VN';
            msg.rate = 1.0; 

            var voices = window.speechSynthesis.getVoices();
            var vn = voices.find(v => v.lang.includes('vi'));
            if (vn) msg.voice = vn;

            // QUAN TR·ªåNG: ƒê·ªçc xong c√¢u n√†y -> G·ªçi l·∫°i h√†m ƒë·ªÉ ƒë·ªçc c√¢u sau
            msg.onend = function(e) {{
                currentIndex++;
                playNextChunk(); 
            }};
            
            // N·∫øu l·ªói c√¢u n√†y -> B·ªè qua ƒë·ªçc c√¢u sau lu√¥n
            msg.onerror = function(e) {{
                console.log("L·ªói chunk, skip...");
                currentIndex++;
                playNextChunk();
            }};

            window.speechSynthesis.speak(msg);
        }}
        
        // --- CH·ªú LOAD GI·ªåNG R·ªíI M·ªöI ƒê·ªåC ---
        if (window.speechSynthesis.getVoices().length === 0) {{
            window.speechSynthesis.addEventListener('voiceschanged', function() {{
                playNextChunk();
            }});
        }} else {{
            playNextChunk();
        }}
        
        // --- ANTI SLEEP (GI·ªÆ K·∫æT N·ªêI) ---
        if (window.speechInterval) clearInterval(window.speechInterval);
        window.speechInterval = setInterval(function() {{
            if (window.speechSynthesis.speaking) {{
                window.speechSynthesis.pause();
                window.speechSynthesis.resume();
            }}
        }}, 8000);

    </script>
    """
    components.html(html, height=0)

# --- GIAO DI·ªÜN CH√çNH ---
st.set_page_config(page_title="PDF Smooth V30", layout="centered")

st.markdown("<h3 style='text-align: center;'>üì± PDF Smooth (V30)</h3>", unsafe_allow_html=True)

uploaded_file = st.file_uploader("Ch·ªçn file PDF:", type="pdf")

if uploaded_file:
    if 'curr_page' not in st.session_state: st.session_state.curr_page = 1
    if 'auto' not in st.session_state: st.session_state.auto = False

    doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
    total = doc.page_count
    uploaded_file.seek(0)
    bytes_data = uploaded_file.read()

    # --- CH·ªåN TRANG ---
    st.write("---")
    col_jump, col_label = st.columns([2, 1])
    
    with col_jump:
        new_page = st.number_input(
            "Nh·∫≠p s·ªë trang:", 
            min_value=1, 
            max_value=total, 
            value=st.session_state.curr_page,
            label_visibility="collapsed"
        )
    with col_label:
        st.markdown(f"** / {total} trang**")

    if new_page != st.session_state.curr_page:
        st.session_state.curr_page = new_page
        st.rerun()

    # --- N√öT ƒêI·ªÄU H∆Ø·ªöNG ---
    c1, c2 = st.columns(2)
    with c1:
        if st.button("‚¨ÖÔ∏è L√ôI L·∫†I", use_container_width=True):
            if st.session_state.curr_page > 1:
                st.session_state.curr_page -= 1
                st.rerun()
    with c2:
        if st.button("TI·∫æP THEO ‚û°Ô∏è", type="primary", use_container_width=True):
            if st.session_state.curr_page < total:
                st.session_state.curr_page += 1
                st.session_state.auto = True
                st.rerun()

    # --- PLAY / STOP ---
    if st.session_state.auto:
        if st.button("üü• D·ª™NG ƒê·ªåC", use_container_width=True):
            components.html("<script>window.speechSynthesis.cancel()</script>", height=0)
            st.session_state.auto = False
            st.rerun()
    else:
        if st.button("‚ñ∂Ô∏è B·∫ÆT ƒê·∫¶U T·ª∞ ƒê·ªòNG", use_container_width=True):
            st.session_state.auto = True
            st.rerun()

    # --- HI·ªÇN TH·ªä ·∫¢NH ---
    img, text = get_page_lite(bytes_data, st.session_state.curr_page)
    
    if img:
        st.image(img, use_container_width=True)
    
    # --- X·ª¨ L√ù ƒê·ªåC ---
    if st.session_state.auto:
        # √âP ƒê·ªåC: K·ªÉ c·∫£ √≠t ch·ªØ c≈©ng ƒë·ªçc
        if text:
            st.toast(f"üîä ƒêang ƒë·ªçc trang {st.session_state.curr_page}...")
            mobile_speak_smooth(text)
            
            # Hi·ªÉn th·ªã text m·ªù m·ªù b√™n d∆∞·ªõi ƒë·ªÉ bi·∫øt n√≥ ƒëang ƒë·ªçc c√°i g√¨
            with st.expander("Xem vƒÉn b·∫£n ƒëang ƒë·ªçc"):
                st.write(text)
        else:
            st.warning("Trang tr·∫Øng. Chuy·ªÉn trang...")
            time.sleep(1)
            if st.session_state.curr_page < total:
                st.session_state.curr_page += 1
                st.rerun()
